import streamlit as st
import pandas as pd
import json
import asyncio
import aiohttp
import time
import random

# è¨­å®šé é¢è³‡è¨Š
st.set_page_config(page_title="HTTP Status Checker Pro", layout="wide", page_icon="ğŸ›¡ï¸")

st.title("ğŸ›¡ï¸ åœ–ç‰‡ HTTP ç‹€æ…‹æª¢æŸ¥å·¥å…· (æŠ—å°é–ç‰ˆ)")
st.markdown("""
æ­¤ç‰ˆæœ¬é‡å° **å¤§é‡ URL** é€²è¡Œäº†å„ªåŒ–ï¼š
1. **å½è£ç€è¦½å™¨** (User-Agent) é¿å…è¢«è­˜åˆ¥ç‚ºæ©Ÿå™¨äººã€‚
2. **è‡ªå‹•é‡è©¦** (ç•¶é‡åˆ° 504/429 éŒ¯èª¤æ™‚æœƒè‡ªå‹•é‡è©¦)ã€‚
3. **åˆ†æ‰¹è™•ç†** (æ¯æ‰¹æ¬¡ä¸­é–“æœƒæœ‰ç·©è¡æ™‚é–“ï¼Œé¿å…è¢«é˜²ç«ç‰†å°é– IP)ã€‚
""")

# --- å½è£ Header ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
}

# --- éåŒæ­¥æª¢æŸ¥æ ¸å¿ƒé‚è¼¯ (å«é‡è©¦æ©Ÿåˆ¶) ---
async def check_http_status(session, url, semaphore):
    """éåŒæ­¥æª¢æŸ¥ HTTP Status Codeï¼ŒåŒ…å«é‡è©¦é‚è¼¯"""
    if not url or not isinstance(url, str) or not url.startswith('http'):
        return {"url": url, "code": 0, "status": "âš ï¸ Invalid URL", "reason": "Malformed URL"}
    
    # é™åˆ¶åŒæ™‚åŸ·è¡Œæ•¸é‡ (Semaphore)
    async with semaphore:
        retries = 3 # è¨­å®šé‡è©¦æ¬¡æ•¸
        for attempt in range(retries):
            try:
                # ä½¿ç”¨ HEAD è«‹æ±‚
                async with session.head(url, headers=HEADERS, timeout=10, allow_redirects=True) as response:
                    code = response.status
                    reason = response.reason
                    
                    # å¦‚æœé‡åˆ° 504 (Timeout) æˆ– 429 (Too Many Requests)ï¼Œä¸”ä¸æ˜¯æœ€å¾Œä¸€æ¬¡å˜—è©¦ -> ç­‰å¾…å¾Œé‡è©¦
                    if code in [504, 429, 503] and attempt < retries - 1:
                        wait_time = (attempt + 1) * 2 # ç­‰å¾… 2ç§’, 4ç§’...
                        await asyncio.sleep(wait_time)
                        continue 

                    # ç‹€æ…‹ç¢¼åˆ†é¡
                    if code == 200:
                        status_icon = "ğŸŸ¢ 200 OK"
                    elif code == 404:
                        status_icon = "ğŸ”´ 404 Not Found"
                    elif code == 410:
                        status_icon = "ğŸšï¸ 410 Gone"
                    elif code == 403:
                        status_icon = "ğŸŸ  403 Forbidden"
                    elif code >= 500:
                        status_icon = f"ğŸ”¥ {code} Server Error"
                    else:
                        status_icon = f"âšª {code} {reason}"

                    return {
                        "url": url, 
                        "code": code, 
                        "status": status_icon, 
                        "reason": reason
                    }
            
            except (asyncio.TimeoutError, aiohttp.ClientError) as e:
                # ç¶²è·¯éŒ¯èª¤ä¹Ÿé‡è©¦
                if attempt < retries - 1:
                    await asyncio.sleep(2)
                    continue
                return {"url": url, "code": 0, "status": "âŒ Connection Error", "reason": str(e)}
            except Exception as e:
                return {"url": url, "code": 0, "status": "âŒ Error", "reason": str(e)}

async def process_batch_smart(urls, max_concurrency, progress_bar, status_text):
    """æ™ºèƒ½åˆ†æ‰¹è™•ç†ï¼Œé˜²æ­¢è¢«å°é–"""
    
    # é™åˆ¶åŒæ™‚é€£ç·šæ•¸ (Semaphore æ˜¯æ›´åš´æ ¼çš„æ§åˆ¶)
    semaphore = asyncio.Semaphore(max_concurrency)
    
    # TCP Connector è¨­å®š
    connector = aiohttp.TCPConnector(limit=max_concurrency, ssl=False)
    
    timeout = aiohttp.ClientTimeout(total=None, connect=10, sock_read=10)

    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        tasks = []
        results = []
        total = len(urls)
        
        # å°‡ URL åˆ†æˆå°å¡Š (Chunks)ï¼Œä¾‹å¦‚æ¯ 50 å€‹ä¸€çµ„
        chunk_size = 50 
        
        for i in range(0, total, chunk_size):
            chunk_urls = urls[i : i + chunk_size]
            chunk_tasks = []
            
            # å»ºç«‹é€™ä¸€æ‰¹çš„ä»»å‹™
            for url in chunk_urls:
                task = check_http_status(session, url, semaphore)
                chunk_tasks.append(task)
            
            # åŸ·è¡Œé€™ä¸€æ‰¹
            batch_results = await asyncio.gather(*chunk_tasks)
            results.extend(batch_results)
            
            # æ›´æ–°é€²åº¦
            current_count = min(i + chunk_size, total)
            percent = current_count / total
            progress_bar.progress(percent)
            status_text.text(f"ğŸ›¡ï¸ æƒæä¸­ (å·²å®Œæˆ {current_count}/{total})... ä¼‘æ¯é˜²å°é–ä¸­ â˜•")
            
            # é—œéµï¼šæ¯ä¸€æ‰¹åšå®Œå¾Œï¼Œç¨å¾®ä¼‘æ¯ä¸€ä¸‹ (0.5 ~ 1.5 ç§’éš¨æ©Ÿ)
            # é€™èƒ½å¤§å¹…æ¸›å°‘ 504 å‡ºç¾çš„æ©Ÿç‡
            if i + chunk_size < total:
                await asyncio.sleep(random.uniform(0.5, 1.5))
            
        return results

def extract_url(json_str):
    try:
        data = json.loads(json_str)
        return data.get('entries', {}).get('url')
    except:
        return None

# --- UI ä»‹é¢ ---
tab1, tab2 = st.tabs(["ğŸ“‚ æ‰¹é‡ CSV æª¢æŸ¥", "ğŸ” å–®ä¸€ç¶²å€æ¸¬è©¦"])

# === Tab 1: æ‰¹é‡æª¢æŸ¥ ===
with tab1:
    st.header("ä¸Šå‚³ CSV æª¢æŸ¥ (å®‰å…¨æ¨¡å¼)")
    
    with st.expander("âš™ï¸ è¨­å®šèˆ‡æ•ˆèƒ½", expanded=True):
        st.caption("å¦‚æœä»ç„¶å‡ºç¾å¤§é‡ 504ï¼Œè«‹å˜—è©¦èª¿ä½æ­¤æ•¸å€¼")
        concurrency = st.slider("åŒæ™‚é€£ç·šæ•¸ (å»ºè­° 20-50)", 10, 100, 30)
    
    uploaded_file = st.file_uploader("é¸æ“‡æ‚¨çš„ CSV æª”æ¡ˆ", type=["csv"], key="smart_check_uploader")

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            if 'mainImage' in df.columns:
                with st.spinner("æ­£åœ¨è§£æ JSON ç¶²å€..."):
                    df['extracted_url'] = df['mainImage'].apply(extract_url)
                    unique_urls = df['extracted_url'].dropna().unique().tolist()
                
                st.info(f"ğŸ“Š æº–å‚™æª¢æŸ¥ {len(unique_urls)} å€‹ç¶²å€ã€‚ç³»çµ±å°‡è‡ªå‹•åˆ†æ‰¹è™•ç†ä»¥é¿å… 504 éŒ¯èª¤ã€‚")

                if st.button("ğŸš€ é–‹å§‹å®‰å…¨æƒæ"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    start_time = time.time()

                    # åŸ·è¡Œæ™ºèƒ½æ‰¹æ¬¡è™•ç†
                    results = asyncio.run(process_batch_smart(unique_urls, concurrency, progress_bar, status_text))
                    
                    duration = time.time() - start_time
                    progress_bar.progress(1.0)
                    status_text.text(f"âœ… å®Œæˆï¼")
                    st.success(f"ğŸ‰ æª¢æŸ¥å®Œç•¢ï¼è€—æ™‚: {duration:.2f} ç§’")

                    results_df = pd.DataFrame(results)
                    
                    # çµ±è¨ˆçœ‹æ¿
                    c1, c2, c3, c4, c5 = st.columns(5)
                    c1.metric("ğŸŸ¢ 200 æ­£å¸¸", len(results_df[results_df['code'] == 200]))
                    c2.metric("ğŸ”´ 404 å¤±æ•ˆ", len(results_df[results_df['code'] == 404]))
                    c3.metric("ğŸšï¸ 410 ç§»é™¤", len(results_df[results_df['code'] == 410]))
                    c4.metric("ğŸ”¥ 504/Timeout", len(results_df[results_df['code'].isin([504, 408])]))
                    c5.metric("âŒ å…¶ä»–", len(results_df[~results_df['code'].isin([200, 404, 410, 504, 408])]))

                    if len(results_df[results_df['code'] == 504]) > 0:
                        st.warning("âš ï¸ åµæ¸¬åˆ° 504 Gateway Timeoutã€‚é€™è¡¨ç¤ºä¼ºæœå™¨å¿™ç¢Œæˆ–å°é–è«‹æ±‚ã€‚è«‹å˜—è©¦èª¿ä½ã€ŒåŒæ™‚é€£ç·šæ•¸ã€å†è©¦ä¸€æ¬¡ã€‚")

                    st.subheader("è©³ç´°çµæœ")
                    all_statuses = sorted(results_df['status'].unique())
                    filter_option = st.multiselect("éæ¿¾ç‹€æ…‹ç¢¼:", options=all_statuses, default=all_statuses)
                    
                    filtered_df = results_df[results_df['status'].isin(filter_option)]
                    st.dataframe(
                        filtered_df, 
                        column_config={
                            "url": st.column_config.LinkColumn("åœ–ç‰‡ç¶²å€"),
                            "status": "ç‹€æ…‹",
                            "reason": "ä¼ºæœå™¨è¨Šæ¯"
                        },
                        use_container_width=True
                    )
                    
                    csv = results_df.to_csv(index=False).encode('utf-8')
                    st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±å‘Š", data=csv, file_name="http_status_report.csv", mime="text/csv")
            else:
                st.error("CSV ç¼ºå°‘ 'mainImage' æ¬„ä½ï¼")
        except Exception as e:
            st.error(f"éŒ¯èª¤: {e}")

# === Tab 2: å–®ä¸€æª¢æŸ¥ ===
with tab2:
    st.header("å–®ä¸€ç¶²å€ HTTP æ¸¬è©¦")
    url_input = st.text_input("è¼¸å…¥åœ–ç‰‡ç¶²å€", placeholder="https://...")
    
    if st.button("æª¢æŸ¥ç‹€æ…‹"):
        if url_input:
            async def run_single():
                semaphore = asyncio.Semaphore(1) # å–®ä¸€æª¢æŸ¥ä¸éœ€è¦é™åˆ¶
                async with aiohttp.ClientSession() as session:
                    return await check_http_status(session, url_input, semaphore)
            
            res = asyncio.run(run_single())
            
            if res['code'] == 200:
                st.success(f"ç‹€æ…‹: {res['status']}")
                st.image(url_input, width=300, caption="åœ–ç‰‡é è¦½")
            elif res['code'] == 404:
                st.error(f"ç‹€æ…‹: {res['status']}")
                st.warning("é€™å¼µåœ–ç‰‡å·²ç¶“ä¸å­˜åœ¨ä¼ºæœå™¨ä¸Š (Not Found)ã€‚")
            elif res['code'] == 410:
                st.error(f"ç‹€æ…‹: {res['status']}")
                st.warning("é€™å¼µåœ–ç‰‡å·²è¢«æ°¸ä¹…ç§»é™¤ (Gone)ã€‚")
            else:
                st.warning(f"ç‹€æ…‹: {res['status']} | è¨Šæ¯: {res['reason']}")
